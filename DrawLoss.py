#%%
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

#%%
train_loss = [0.8540464043617249,0.588474452495575,0.5672479271888733,0.5601412653923035,0.5542328953742981,0.5490387082099915,0.5444406867027283,0.5403481125831604,0.5366865992546082,0.5333932638168335,0.5304203033447266,0.5277297496795654,0.5252905488014221,0.523080587387085,0.5210812091827393,0.5192727446556091,0.5176360607147217,0.5161523222923279,0.5148006677627563,0.5135613679885864,0.5124150514602661,0.5113475918769836,0.5103409290313721,0.5093834400177002,0.5084649324417114,0.5075747966766357,0.506706953048706,0.5058569312095642,0.5050161480903625,0.5041847825050354,0.5033576488494873,0.502532958984375,0.5017088651657104,0.5008835792541504,0.5000554323196411,0.49922236800193787,0.49838533997535706,0.49754247069358826,0.49669167399406433,0.4958345890045166,0.4949699938297272,0.49409493803977966,0.49321064352989197,0.4923141598701477,0.49140551686286926,0.4904841184616089,0.48955032229423523,0.4886036217212677,0.4876437187194824,0.48667025566101074,0.4856838881969452,0.4846843183040619,0.48367297649383545,0.482648640871048,0.4816129803657532,0.48056289553642273,0.4795010983943939,0.47842568159103394,0.4773384928703308,0.47623807191848755,0.47512683272361755,0.4740042984485626,0.4728698134422302,0.471725732088089,0.47057193517684937,0.4694080054759979,0.4682362675666809,0.46705639362335205,0.4658680260181427,0.46467289328575134,0.46347156167030334,0.46226179599761963,0.46104589104652405,0.4598229229450226,0.45859235525131226,0.45735493302345276,0.45611071586608887,0.4548594057559967,0.45360174775123596,0.45233747363090515,0.4510667622089386,0.4497907757759094,0.448510080575943,0.4472244679927826,0.44593480229377747,0.4446413218975067,0.4433439075946808,0.44204357266426086,0.44074153900146484,0.4394375681877136]
validation_loss = [0.44732868671417236,0.3957529366016388,0.3907160460948944,0.38741356134414673,0.3848046362400055,0.38255512714385986,0.38043516874313354,0.3784044086933136,0.37653955817222595,0.37491804361343384,0.3735537827014923,0.37247464060783386,0.37162744998931885,0.37094950675964355,0.370401531457901,0.36995258927345276,0.3695703446865082,0.3692399859428406,0.3689500689506531,0.36868584156036377,0.36844950914382935,0.3682311177253723,0.3680265247821808,0.3678392171859741,0.3676702380180359,0.36752066016197205,0.36738622188568115,0.3672676980495453,0.3671530783176422,0.3670409321784973,0.3669333755970001,0.36683088541030884,0.3667343854904175,0.36664050817489624,0.36654749512672424,0.3664614260196686,0.3663816750049591,0.3662991523742676,0.36622506380081177,0.3661552369594574,0.3660869598388672,0.3660195767879486,0.3659551441669464,0.365885853767395,0.365814208984375]
testing_loss = [0.45376700162887573,0.4009167551994324,0.3964367210865021,0.3936343193054199,0.39140835404396057,0.38942432403564453,0.38757145404815674,0.3858104944229126,0.38416463136672974,0.3826996982097626,0.3814891576766968,0.3804791569709778,0.3796488046646118,0.3789699673652649,0.378395676612854,0.377900093793869,0.3774752616882324,0.37710073590278625,0.3767659068107605,0.3764658272266388,0.37618863582611084,0.37593647837638855,0.37571051716804504,0.3755112588405609,0.3753363788127899,0.3751670718193054,0.3750247657299042,0.3749065697193146,0.374801903963089,0.3747124671936035,0.37463971972465515,0.3745769262313843,0.3745304346084595,0.37450647354125977,0.3744926452636719,0.37448909878730774,0.37449172139167786,0.37449315190315247,0.37448689341545105,0.37447530031204224,0.3744643032550812,0.37445589900016785,0.37444421648979187,0.3744274079799652,0.37441906332969666]

# 1 GRU for intra review
last_val_loss = [0.8313842507408242,0.8140023194211318,0.8120195499564241,0.81087318471073,0.8085704075882818,0.8048184183189544,0.7990983848971638,0.7933549005340517,0.7899347204744868,0.7882605115756591,0.7874444323632476,0.7869328441914928,0.7846811961232913,0.7852487876315152,0.7872834947806201,0.7889666220860849,0.7895134856383159,0.7887437119047134,0.7890433076673156,0.7878056923363798,0.7910609305478083,0.7925887302681944,0.7936838942603278,0.7946264044485025,0.7971282227140771,0.7991699801157317,0.7989341243861461,0.7997854412603171,0.7990957919474325,0.7986757097158129,0.7970761916143896,0.7963978367608326,0.7977999567343766,0.7983643123519247,0.7973756802603866,0.797638155049829,0.7943183992672445,0.793921839877177,0.7939637127290119,0.7921720584073723,0.7929896223499309,0.7903584760228252,0.7940339809443884,0.7902100630389373,0.7906302706209646,0.7905077167182344,0.789582586937752,0.789824136025133,0.790136985538824,0.7849971510847088,0.786361031537096]
#%%
trl_len = len(train_loss)
val_len = len(validation_loss)
tel_len = len(testing_loss)
lval_len = len(last_val_loss)

trl_len, val_len, tel_len
#%%
y_train = [index for index in range(trl_len)]
y_validation = [index*2 for index in range(val_len)]
y_testing = [index*2 for index in range(tel_len)]
y_last_validation = [index*2 for index in range(lval_len)]

#%%
fig = plt.figure(figsize=(6, 4))
plt.plot(y_train, train_loss , label='Train loss')
plt.plot(y_validation, validation_loss , label='Val. loss')
plt.plot(y_testing, testing_loss , label='Test loss')

plt.plot(y_last_validation, last_val_loss , label='One IntraGRU')

plt.legend(loc='best', framealpha=0.5, prop={'size': 'large', 'family': 'monospace'})

# plt.show()

fig.savefig('Loss.png', facecolor='w')
plt.clf()


# %%
